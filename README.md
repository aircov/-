# recmd_project
## data_nlp/day1

Keras情感分析（Sentiment Analysis）实战---自然语言处理技术

情感分析任务其实是个**分类任务**，给模型输入一句话，让它判断这句话的情感是积极的，消极的，还是中性的。例子如下：
 输入：的确是专业，用心做，出品方面都给好评。
 输出：2
 输出可以是[0,1,2]其中一个，0表示情感消极，1表示情感中性，2表示情感积极。

#### 情感分析算法简介

分类任务的算法，想必大家都很熟悉：SVM，Logistic，Tree等。可是对于文本分类来说，最重要的是如何将一句话的映射到向量空间，同时保持其语义特征。所以文本的**向量化表示**是最最重要的一个环节。而文本的向量化就是涉及到**Word Embedding**技术和**深度学习(Deep Learning)**技术。

**Word Embedding**指的是把文本转换成计算机能处理的向量，而其中难点的是：将文本向量化时如何保持句子原有的语义。早期word embedding使用的是Bag of Words，TF-IDF等，这些算法有个共同的特点：就是没有考虑语序以及上下文关系。而近几年发展出来的**Word2Vector ，Glove**等考虑到了文本的上下文关系。今年NLP领域大放异彩的**BERT**就是在文本向量化上做出了重大的突破。

人工特征的挖掘是个极为费脑费时的过程，**深度学习**模型可以将特征工程自动化，通过神经网络自动做特征的表示学习。在NLP领域中,**RNN**(LSTM,GRU)，**CNN**，**Transformer**等各路深度学习模型各显神通，凭借他们强大的特征表示能力，在很多任务中都吊打人工特征（吹得  有些夸张了，没收住）。不过人工特征有时还是很重要的。



本次的项目实战的总体架构可分为两个步骤：
（1）采用Word2Vector技术去训练词向量；
（2）采用BiLSTM去做特征的表示学习。

#### 训练词向量

将所有的评论文本数据用来训练词向量，这里使用的gensim中的Word2Vec,原理是的Skip-gram。这里对词向量的原理不多介绍，总之，这一步将一个词映射成一个100维的向量，并且考虑到了上下文的语义。这里直接将上一部得到的句子列表传给train_word2vec函数就可以了，同时需要定义一个词向量文件保存路径。模型保存后，以后使用就不需要再次训练，直接加载保存好的模型就可以啦。

#### 数据预处理

这里定义了一些数据处理和变换方法。

###### 获取词向量矩阵和词典

```undefined
w2id,embedding_weights = generate_id2wec(model)
```

这一步主要是为了拿到传给后续情感分析模型的词典（w2id）和词向量矩阵embedding_weights，
 **w2id格式**如下：{
 ...
 '一两天': 454,
 '一两年': 455,
 '一两次': 456,
 '一个': 457,
 '一个个': 458,
 '一个劲': 459,
 ...
 '不一会': 984,
 '不上': 985,
 '不下': 986,
 '不严': 987,
 '不为过': 988,
 '不久': 989,
 }

embedding_weights格式如下:

[[ 0.        ,  0.        ,  0.        , ...,  0.        ,

0.        ,  0.        ],

[-1.1513499 , -0.00520114,  1.65645397, ...,  0.50586915,

-0.03466858,  0.84113288],

[ 0.01824509, -0.23613754, -0.47191045, ..., -0.16491373,

-0.25222906, -0.00384654],

...,

[ 0.10879639,  0.05459598, -0.02946772, ..., -0.17389177,

0.10144144,  0.21539673]]

这个矩阵保存了上面通过Word2Vector方法训练的词向量，每个词通过其在词典（w2id）中的index索引到对应得词向量，此矩阵将作为参数传给后续的情感分析模型。

将数据变换成模型能够处理的格式。
 原始数据格式如下：
 sen :不错，品种齐全，上菜很快，味道也不错
 label ：2

执行上面代码后句子数据变成如下格式：
 输入：[0，0，0......,31,43,12,4,65,12,233,11,1391,131,4923,1233]
 输出：[0，0，1]

## HotWords

爬虫代码，自动爬取百度热搜，微博热搜，存储在mysql；

mysql数据增量/全量保存到elasticsearch；

save_to_redis：将mysql中query词和热度值保存在redis，hash结构，便于在搜索联想的时候按照heat排序。

## Search

搜索接口